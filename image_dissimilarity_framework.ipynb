{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "037184f3",
   "metadata": {},
   "source": [
    "#### Face Recognition â€“ Unlock Your Application With Your Face!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa4f69f",
   "metadata": {},
   "source": [
    "##### 1. Create Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db28cd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dependencies\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import uuid\n",
    "import os\n",
    "import cv2\n",
    "import itertools\n",
    "import numpy as np\n",
    "from time import time\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from random import uniform\n",
    "import time\n",
    "from IPython.display import display, clear_output\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "drawing_details = mp.solutions.drawing_utils\n",
    "hands_details = mp.solutions.hands\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh_images = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=2,\n",
    "                                         min_detection_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762dbf8e",
   "metadata": {},
   "source": [
    "##### 2. First Image and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fac96935",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:9: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:9: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_16080\\1688979310.py:9: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Samples Complete and first image is selected\n",
      "Model trained sucessefully\n",
      "Loading . . . . \n",
      "Facial coordinates are saved\n"
     ]
    }
   ],
   "source": [
    "# Load HAAR face classifier\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "# Load functions\n",
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return None \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "    return cropped_face\n",
    "# Initialize Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "# Collect 100 samples of your face from webcam input\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('Face Cropper', frame)\n",
    "    if face_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(frame), (200, 200))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        # Save file in specified directory with unique name\n",
    "        file_name_path = 'image/' + str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "        # Put count on images and display live count\n",
    "        #cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        if count == 19:\n",
    "            fi = frame\n",
    "    else:\n",
    "        #print(\"Face not found\")\n",
    "        pass\n",
    "    if cv2.waitKey(1) == 13 or count == 100: #13 is the Enter Key\n",
    "        break        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples Complete and first image is selected\")\n",
    "\n",
    "#Training model\n",
    "\n",
    "# Get the training data we previously made\n",
    "data_path = 'image/'\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "# Create arrays for training data and labels\n",
    "Training_Data, Labels = [], []\n",
    "# Open training images in our datapath\n",
    "# Create a numpy array for training data\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    Labels.append(i)\n",
    "# Create a numpy array for both training data and labels\n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "# Initialize facial recognizer\n",
    "# model = cv2.face.createLBPHFaceRecognizer()\n",
    "model=cv2.face.LBPHFaceRecognizer_create()\n",
    "# NOTE: For OpenCV 3.0 use cv2.face.createLBPHFaceRecognizer()\n",
    "# Let's train our model \n",
    "model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "print(\"Model trained sucessefully\")\n",
    "\n",
    "print(\"Loading . . . . \")\n",
    "\n",
    "sample_img = cv2.flip(frame, 1)\n",
    "# print(sample_img.shape)\n",
    "w = int(640*1.5)\n",
    "h = int(360*1.5)\n",
    "sample = cv2.resize(sample_img, (w,h), interpolation = cv2.INTER_AREA)\n",
    "face_mesh_results = face_mesh_images.process(sample[:,:,::-1])\n",
    "\n",
    "LEFT_EYE_INDEXES = list(set(itertools.chain(*mp_face_mesh.FACEMESH_LEFT_EYE)))\n",
    "RIGHT_EYE_INDEXES = list(set(itertools.chain(*mp_face_mesh.FACEMESH_RIGHT_EYE)))\n",
    "\n",
    "if face_mesh_results.multi_face_landmarks:\n",
    "\n",
    "    for face_no, face_landmarks1 in enumerate(face_mesh_results.multi_face_landmarks):\n",
    "        li_x0 = []\n",
    "        li_y0 = []\n",
    "        li_z0 = []\n",
    "        for i in range(468):\n",
    "            li_x0.append(face_landmarks1.landmark[i].x)\n",
    "            li_y0.append(face_landmarks1.landmark[i].y)\n",
    "            li_z0.append(face_landmarks1.landmark[i].z)\n",
    "print(\"Facial coordinates are saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8bd823",
   "metadata": {},
   "source": [
    "##### 3. Second Reference Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac14fc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:27: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:27: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_16080\\1581808362.py:27: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    }
   ],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "org = (410, 500)\n",
    "org_s = (40,40)\n",
    "fontScale = 0.7\n",
    "colorr = (0, 0, 255)\n",
    "colorg = (0, 255, 0)\n",
    "colorb = (255, 0, 0)\n",
    "thickness = 1\n",
    "w = int(640*1.5)\n",
    "h = int(360*1.5)\n",
    "counter = 0\n",
    "det = 0\n",
    "\n",
    "sample = cv2.resize(sample_img, (w,h), interpolation = cv2.INTER_AREA)\n",
    "foreground = cv2.flip(sample, 1)\n",
    "alpha = 0.3\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "def face_detector(img, size=0.5):    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as face_mesh:\n",
    "    while True:\n",
    "        ret, frame = cap.read()  \n",
    "        image, face = face_detector(frame) \n",
    "        background = cv2.resize(image, (w,h), interpolation = cv2.INTER_AREA)\n",
    "        try:\n",
    "            det +=1\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "            # Pass face to prediction model\n",
    "            # \"results\" comprises of a tuple containing the label and the confidence value\n",
    "            results = model.predict(face)\n",
    "            if results[1] < 500:\n",
    "                confidence = int( 100 * (1 - (results[1])/400) )\n",
    "                display_string = str(confidence) + '% Confident it is User'     \n",
    "#             cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "            #If face is recognized \n",
    "           \n",
    "            if det > 50:\n",
    "                det == 0\n",
    "            #Face alignment \n",
    "            if confidence > 78:\n",
    "                added_image = cv2.putText(image, \"Face is matched\", (60, 100), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "                image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "            # To improve performance, optionally mark the image as not writeable to\n",
    "            # pass by reference.\n",
    "                image.flags.writeable = False\n",
    "                results = face_mesh.process(image)\n",
    "                if results.multi_face_landmarks:\n",
    "                    for face_landmarks in results.multi_face_landmarks:\n",
    "                        mp_drawing.draw_landmarks(\n",
    "                            image=image,\n",
    "                            landmark_list=face_landmarks,\n",
    "                            connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                            landmark_drawing_spec=drawing_spec,\n",
    "                            connection_drawing_spec=drawing_spec)\n",
    "                        li_x = []\n",
    "                        li_y = []\n",
    "                        li_z = []\n",
    "                        for i in range(468):\n",
    "                            li_x.append((li_x0[i] - face_landmarks.landmark[i].x)**2)\n",
    "                            li_y.append((li_y0[i] - face_landmarks.landmark[i].y)**2)        \n",
    "                        clear_output(wait=True)\n",
    "                        target_x = (sum(li_x))**(1/2)\n",
    "                        target_y = (sum(li_y))**(1/2)\n",
    "                        scaled = 5*(target_x+target_y)\n",
    "    #                     print(\"Similarity: \",scaled)\n",
    "                _image = cv2.addWeighted(foreground,alpha,background,1-alpha,0)\n",
    "                simi = \"Similarity: \"\n",
    "                scal = int(scaled)\n",
    "\n",
    "                # Draw the face mesh annotations on the image.\n",
    "                image.flags.writeable = False\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "                if scaled<11:\n",
    "                    added_image = cv2.putText(_image, 'Face alignment is correct' , org, font, fontScale, colorg, thickness, cv2.LINE_AA)\n",
    "                    added_image = cv2.putText(added_image,  f'{simi} \"{scal}\"', org_s, font, fontScale, colorb, thickness, cv2.LINE_AA)\n",
    "                    cv2.namedWindow('MediaPipe FaceMesh', cv2.WINDOW_NORMAL)\n",
    "                    cv2.resizeWindow('MediaPipe FaceMesh', w, h)\n",
    "                    cv2.imshow('MediaPipe FaceMesh', added_image)\n",
    "                    counter +=1\n",
    "                    \n",
    "                    if counter > 100:\n",
    "                        added_image = cv2.putText(_image, 'Please be steady' , (370,200), font, 1, colorg, 2, cv2.LINE_AA)                        \n",
    "                        added_image = cv2.putText(_image, 'Press Enter to capture' , (150,300), font, 2, colorg, 5, cv2.LINE_AA)\n",
    "                        cv2.namedWindow('MediaPipe FaceMesh', cv2.WINDOW_NORMAL)\n",
    "                        cv2.resizeWindow('MediaPipe FaceMesh', w, h)\n",
    "                        cv2.imshow('MediaPipe FaceMesh', _image)\n",
    "                          \n",
    "                else: \n",
    "                    added_image = cv2.putText(_image, 'Face alignment is incorrect', org, font, fontScale, colorr, thickness, cv2.LINE_AA)\n",
    "                    added_image = cv2.putText(added_image, f'{simi} \"{scal}\"', org_s, font, fontScale, colorb, thickness, cv2.LINE_AA)\n",
    "                    cv2.namedWindow('MediaPipe FaceMesh', cv2.WINDOW_NORMAL)\n",
    "                    cv2.resizeWindow('MediaPipe FaceMesh', w, h)\n",
    "                    cv2.imshow('MediaPipe FaceMesh', added_image)\n",
    "\n",
    "            else:\n",
    "                added_image = cv2.putText(_image, \"Face Mismatch\",  (60, 100), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "                cv2.namedWindow('MediaPipe FaceMesh', cv2.WINDOW_NORMAL)\n",
    "                cv2.resizeWindow('MediaPipe FaceMesh', w, h)\n",
    "                cv2.imshow('MediaPipe FaceMesh', added_image)\n",
    "\n",
    "        except:\n",
    "            if counter > 100:\n",
    "                pass\n",
    "            else:\n",
    "                added_image = cv2.addWeighted(foreground,alpha,background,1-alpha,0)\n",
    "                added_image = cv2.putText(added_image, \"Please Align the face\", (350, 200) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "                cv2.namedWindow('MediaPipe FaceMesh', cv2.WINDOW_NORMAL)\n",
    "                cv2.resizeWindow('MediaPipe FaceMesh', w, h)\n",
    "                cv2.imshow('MediaPipe FaceMesh', added_image )\n",
    "    \n",
    "        if cv2.waitKey(1) == 13 and counter > 100: #13 is the Enter Key\n",
    "            time.sleep(4)\n",
    "            break        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25b562a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_recognition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
